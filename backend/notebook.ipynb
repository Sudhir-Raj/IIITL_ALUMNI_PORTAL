{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUm_hQuShXwb"
      },
      "source": [
        "# Recommendation System"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-j5eJgf6hXwg"
      },
      "source": [
        "In this recommendation system I have used Kaggle dataset named Post Recommendation System Here is the link of that : https://www.kaggle.com/vatsalparsaniya/post-pecommendation\n",
        "\n",
        "It will consume a user_id and check the history or like or vote he has given to post and check other users simliarities and then recommend posts.\n",
        "\n",
        "Here we go::::::::::::"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nwhjr-3VhXwg"
      },
      "outputs": [],
      "source": [
        "#importing relevant libraries\n",
        "%pip install pandas\n",
        "%pip install numpy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "esebfjIEhXwi"
      },
      "outputs": [],
      "source": [
        "#Datasets Importing \n",
        "#post_data consists of post details like post_id, title, category\n",
        "#user_data consists of user's information\n",
        "#view_data consists of which user view which post\n",
        "\n",
        "post_data = pd.read_csv(r'postnew_data (1).csv')\n",
        "user_data = pd.read_csv(r'user_data (2).csv')\n",
        "view_data = pd.read_csv(r'view_data (1).csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2zug6JGirQ5"
      },
      "source": [
        "# New section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqfPGzTt6HMK"
      },
      "source": [
        "#drop the irrevelent features i.e category and title is important but not for this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VOGopyQvhXwj"
      },
      "outputs": [],
      "source": [
        "post_data = post_data.drop(['title','category'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-F-GixBQhXwk"
      },
      "outputs": [],
      "source": [
        "post_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FPojA3W5hXwk"
      },
      "outputs": [],
      "source": [
        "user_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Mi5BmFthXwl"
      },
      "outputs": [],
      "source": [
        "view_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w8sV_p4YhXwl"
      },
      "outputs": [],
      "source": [
        "post_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s8wYtDpShXwm"
      },
      "outputs": [],
      "source": [
        "post_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S3XPWtUlhXwm"
      },
      "outputs": [],
      "source": [
        "#Making Recommendation system is not a supervised learning right that consist of label but it is \n",
        "# unsupervised learning so we have to add likes or make it valuable that means the user rate it valuable\n",
        "# in terms of rating like out of 5 okay\n",
        "# I add up it.\n",
        "\n",
        "dataframe = pd.DataFrame(view_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hsmeuFCjhXwn"
      },
      "outputs": [],
      "source": [
        "dataframe[\"Valuable\"] = np.random.randint(1, 6, len(dataframe))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NyBq4NxyhXwn"
      },
      "outputs": [],
      "source": [
        "#this is our data right now.\n",
        "dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fmi6-AFfhXwn"
      },
      "outputs": [],
      "source": [
        "# in this cell we are merging view data and the dataframe I have made of post data. in this post id is common.\n",
        "\n",
        "df = pd.merge(dataframe, post_data ,on='post_id')\n",
        "df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "POhIWWu0hXwn"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "riKcqp0ShXwo"
      },
      "outputs": [],
      "source": [
        "#drop the irrevelent features time_stamp is not \n",
        "#important right now.\n",
        "data = df.drop('time_stamp', axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QoKUfG-ThXwo"
      },
      "outputs": [],
      "source": [
        "data.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GAbqCsdFhXwp"
      },
      "outputs": [],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KFhABp0lhXwp"
      },
      "outputs": [],
      "source": [
        "# In this first we have to make a column here that consists of total ratings a content or a post have. \n",
        "#like 10 Funny ART Quotes has 15 votes given by users.\n",
        "\n",
        "combine_post_rating = data.dropna(axis = 0, subset = ['content'])\n",
        "\n",
        "post_ratingCount = (combine_post_rating.\n",
        "     groupby(by = ['content'])['Valuable'].\n",
        "     count().\n",
        "     reset_index().\n",
        "     rename(columns = {'Valuable': 'totalValuableCount'})\n",
        "     [['content', 'totalValuableCount']]\n",
        "    )\n",
        "post_ratingCount.head() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t6XIDEy7hXwp"
      },
      "outputs": [],
      "source": [
        "\n",
        "#Merge it into our main dataset \n",
        "rating_with_totalValuableCount = combine_post_rating.merge(post_ratingCount, left_on = 'content', right_on = 'content', how = 'left')\n",
        "rating_with_totalValuableCount.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3_vIrZtUhXwq"
      },
      "outputs": [],
      "source": [
        "#It is just how to see data desciption and stuff.\n",
        "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
        "print(post_ratingCount['totalValuableCount'].describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ND8VISChXwq"
      },
      "outputs": [],
      "source": [
        "print(post_ratingCount['totalValuableCount'].quantile(np.arange(.9, 1, .01)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "prT9eU2whXwq"
      },
      "outputs": [],
      "source": [
        "#we have to fix a threshold here that machine will recommend post to user that have votes greater than\n",
        "# the threshold values\n",
        "popularity_threshold = 13\n",
        "rating_popular_post = rating_with_totalValuableCount.query('totalValuableCount >= @popularity_threshold')\n",
        "rating_popular_post.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CPUm9f4LhXwq"
      },
      "outputs": [],
      "source": [
        "rating_popular_post.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8HHCXr9DhXwr"
      },
      "outputs": [],
      "source": [
        "user_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X0QsG_0JhXwr"
      },
      "outputs": [],
      "source": [
        "len(user_data.city.unique())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xeDgfEl1hXwr"
      },
      "source": [
        "Making model from here.\n",
        "we have to make a data matrix like indexes are titles and columns are user id and target is how valuable or how much likes it have."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1yDPXHqyhXwr"
      },
      "source": [
        "Use here cosine similiarity to find the simliarity between user and other users."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-amL_84xhXwr"
      },
      "outputs": [],
      "source": [
        "%pip install scikit-learn\n",
        "%pip install scipy\n",
        "from scipy.sparse import csr_matrix\n",
        "rating_popular_post = rating_popular_post.drop_duplicates(['user_id', 'content'])\n",
        "rating_popular_post_pivot = rating_popular_post.pivot(index = 'content', columns = 'user_id', values = 'Valuable').fillna(0)\n",
        "rating_popular_post_matrix = csr_matrix(rating_popular_post_pivot.values)\n",
        "\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "\n",
        "model_knn = NearestNeighbors(metric = 'cosine', algorithm = 'brute')\n",
        "model_knn.fit(rating_popular_post_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ipkygMwkhXws"
      },
      "outputs": [],
      "source": [
        "rating_popular_post_pivot.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fras7Qm9hXws",
        "outputId": "6294fbd8-b5c5-40e4-9013-683932820218"
      },
      "outputs": [],
      "source": [
        "type(rating_popular_post_pivot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJC1T4eUEu0m"
      },
      "outputs": [],
      "source": [
        "view_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQLk5763hXws"
      },
      "source": [
        "Choose a random users and recommend it a content of post by looking their cosine simliarity scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Qd1WY06bIBGO",
        "outputId": "48f8354e-3126-4e9e-9394-116c1c9580cd"
      },
      "outputs": [],
      "source": [
        "rating_popular_post_pivot\n",
        "rating_popular_post_pivot.to_csv(\"rating_popular_post_pivot.csv\")\n",
        "rating_popular_post_pivot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"rating_popular_post_pivot.csv\")\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-dqOHsdohXws"
      },
      "outputs": [],
      "source": [
        "query_index = np.random.choice(rating_popular_post_pivot.shape[0])\n",
        "print(query_index)\n",
        "distances, indices = model_knn.kneighbors(rating_popular_post_pivot.iloc[query_index,:].values.reshape(1, -1), n_neighbors = 6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qu6dX_2_hXwt"
      },
      "outputs": [],
      "source": [
        "# this is our name of user 3 and posts he has seen or vote it and our task is to recommend it similiar\n",
        "#post\n",
        "rating_popular_post_pivot.index[query_index]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Here we go\n",
        "for i in range(1, len(distances.flatten())):\n",
        "    print(rating_popular_post_pivot.index[indices.flatten()[i]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U-I4PRLQhXwt"
      },
      "outputs": [],
      "source": [
        "\n",
        "%pip install flask\n",
        "%pip install flask_cors\n",
        "import numpy as np \n",
        "from flask import Flask, request, jsonify \n",
        "from flask_cors import CORS, cross_origin \n",
        "import pickle \n",
        "import json \n",
        "\n",
        "app = Flask(__name__)   \n",
        "CORS(app, support_credentials=True) \n",
        "\n",
        "@app.route('/predict',methods=['POST']) \n",
        "@cross_origin(supports_credentials=True) \n",
        "def predict(): \n",
        "    data = request.get_json(force=True) \n",
        "    print(data) \n",
        "#     uid = \"5eece14ffc13ae660900008b\"\n",
        "#     df = view_data[(view_data[\"user_id\"]==uid)]\n",
        "    # df = df.sort_values(\"Valuable\", ascending=False)\n",
        "#     pid = df[\"post_id\"][0]\n",
        "#     pid            \n",
        "    r = {\"result\" : 1 } \n",
        "    response = jsonify(r) \n",
        "    return response          \n",
        "\n",
        "if __name__ == '_main_': \n",
        "    app.run(port=5000, debug=True)\n",
        "# for i in range(1, len(distances.flatten())):\n",
        "#       print('{0}: {1}, with distance of {2}:'.format(i, rating_popular_post_pivot.index[indices.flatten()[i]], distances.flatten()[i]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q39vFepOhXwt"
      },
      "outputs": [],
      "source": [
        "\n",
        "# # import model\n",
        "\n",
        "\n",
        "# import re\n",
        "\n",
        "# # Define a regular expression pattern to match non-printable characters\n",
        "# non_printable = re.compile('[\\x00-\\x08\\x0B\\x0C\\x0E-\\x1F\\x7F-\\x9F]')\n",
        "\n",
        "# # Open the file for reading and writing\n",
        "# # with open('checknonprint.txt', 'r') as input_file, open('output_file.txt', 'w') as output_file:\n",
        "#     # Loop over each line in the input file\n",
        "#     # for line in input_file:\n",
        "#     #     # Remove any non-printable characters from the line\n",
        "#     #     clean_line = non_printable.sub(' ', line)\n",
        "#     #     # Write the cleaned line to the output file\n",
        "#     #     output_file.write(clean_line)\n",
        "\n",
        "# import pickle\n",
        "\n",
        "# # Load the trained model object\n",
        "# model_object = model.model_knn()\n",
        "\n",
        "# # Serialize the object and write it to a pickled file\n",
        "# with open('model.pickle', 'wb') as f:\n",
        "#   for line in f:\n",
        "#         # Remove any non-printable characters from the line\n",
        "#         clean_line = non_printable.sub(' ', line)\n",
        "#         # Write the cleaned line to the output file\n",
        "#         # output_file.write(clean_line)\n",
        "#         pickle.dump(model_object,clean_line)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import pickle\n",
        "\n",
        "with open('model_knn.pkl', 'wb') as f:\n",
        "    pickle.dump(model_knn, f)\n",
        "\n",
        "\n",
        " "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
